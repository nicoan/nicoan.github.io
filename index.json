[{"content":"Having a language that does a lot of checks at compile time is not free, it will impact compilation times. Luckily there are some things we can do to speed things up: Dynamic linking, be careful with code generation and caching dependencies.\nDynamic linking is a somewhat difficult thing to achieve in Rust but not impossible. The main reason is that at the time of writing this (Sept-Oct 2024) Rust does not have its own stable ABI and it must rely on the C binary representation (if we want to inter-operate with other languages or other Rust versions). This has some interesting consequences that we will explore in this post.\nCode generation is when the high level representation of the source code is turned into binary code that can be executed by the machine. Given that the rust compiler uses LLVM, the level of optimizations and the quantity of generated code will affect the compilation speed.\nWhat is Linking? Programs are usually divided into several modules and they have numerous dependencies. Linking is a compilation stage where all the compiled code of those modules needed by a program (and the code of the program itself) is made available in the final executable. We have two ways of linking a program: static and dynamic.\nStatic Linking All the code needed by a program (from external modules and the program itself) is put together in the final executable. This creates fat binaries but it makes the program portable.\nDynamic Linking This type of linking must be supported by the operating system (most, if not all of the major operating systems support this). In this approach, instead of containing all the code needed, the executable contains undefined symbols and a list of objects that contain the code for those symbols.\nThese objects, often referred to as libraries, are binary files used to share binary code between several programs. In Microsoft Windows those files are known as DLLs (dynamically-linked library) and in Unix operating systems (Linux, Mac OS, etc) are known as SOs (shred objects).\nWhen running a dynamically linked executable, the operating system loads the program code along with the libraries in memory and do the final linking.\nThis approach creates “thin” binaries and saves disk and memory space, since the code from the libraries are shared among several applications.\nDifferent linking modes in Rust There are several different linking modes that we can use, producing different kind of shared objects, but in this post we will focus only on one of them: dylib.\nIf we put this configuration in our library crates, the Rust compiler will generate a dynamic library that will be dynamically linked with our executable. Isn’t that what we need? Why do we have other configurations?1 Given that Rust does not have an stable ABI yet, there are no guarantees that the compiled libraries will work if we don’t compile the project with the same Rust version used for compiling the library.\nThis mode is suitable for a project where we have one or more library crates that are used by several binary crates (or other libraries). We will usually compile everything altogether the first time and then recompile only the things we change. If we change the Rust version, we need to recompile everything.\nCompilation stages To generate binary objects, Rust compiler must go through several different stages. I am not going to explain how a compiler works in detail, but having a general idea of what happens will help us identify places where we can work to optimize compile times.\nTo measure compilation times, we will use the built-in cargo tool called timings. This tool will generate a detailed HTML report showing how long every compilation unit takes to compile.\nFrom source code to intermediate representation In the timings report, the stages described below are pictured in light blue in the Grantt chart.\nLexing and parsing The compiler first performs the lexing and parsing stage, where lexing is transforming the source code into an stream of tokens and parsing is generating an AST (Abstract Syntax Tree) from those tokens.\nMacro expansion (generating valid Rust code from the macros) is also done at this stage.\nAST Lowering After the AST is created, it is converted into a High Level Intermediate Representation (HIR), this stage is called AST Lowering. In HIR the compiler does type inference, type checking and resolve traits.\nMIR Lowering When HIR is ready, then we enter the MIR lowering stage, that is, transforming HIR to Middle Level Representation (MIR). In this stage, the famous borrow checking is done, code monomorphization, and some optimizations that will improve code generation and compilation speed in that stage.\nCode generation This stage is pictured in purple in the Grantt chart. When we are here, the compiler already has everything represented in MIR. During this phase, the MIR is transformed into LLVM-IR (LLVM Intermediate Representation) and handled to LLVM.\nLLVM does a lot more of optimizations and generates the assembler and binary code that later is linked into the final object.\nIf you want to learn more about the compilation stages, check this article.\nReducing compile times The toy project In order to show how to optimize compiling times, we are going to use a toy project that consist in one library crate and 40 separate binaries that use the library. You may ask yourself: What kind of project has that structure?! It could be a server-less project containing several cloud functions (like AWS Lambdas) that share functionality through some library crates or some project that consist in several binaries (like GNU Core utilities).\nHow I get the timings The timings found on this posts are the last timing returned by cargo after running 10 times the same compilation, always doing cargo clean before executing cargo build [...]. I compile the project 10 times to verify that on average the compilation times are more or less the same.\nInitial compile times Here are the individual compile times for the toy project. This and further compilations were done in Debian 12, with an i7-6700K and 16GB DDR4 2600Mhz Ram 2:\nThe total time was\nFinished `release` profile [optimized] target(s) in 25.30s And the size of the binaries is about 3.5MB:\nls -l --block-size=KB ./target/release total 143262kB -rwxr-xr-x 2 nico nico 3489kB Sep 16 15:03 bin1 -rwxr-xr-x 2 nico nico 3489kB Sep 16 15:03 bin10 -rw-r--r-- 1 nico nico 1kB Sep 16 15:04 bin10.d -rwxr-xr-x 2 nico nico 3489kB Sep 16 15:03 bin11 -rw-r--r-- 1 nico nico 1kB Sep 16 15:04 bin11.d -rwxr-xr-x 2 nico nico 3489kB Sep 16 15:03 bin12 -rw-r--r-- 1 nico nico 1kB Sep 16 15:04 bin12.d -rwxr-xr-x 2 nico nico 3489kB Sep 16 15:03 bin13 The command used was cargo build --release --timings. You can check the source code of the toy project here.\nRemoving unnecessary dependencies It is common that in a project, the people involved usually forget about removing old dependencies. This happens because when projects are large, it is hard to know if a dependency is not used anymore. Luckily, we can use the -Wunused-crate-dependencies flag that tells us which dependencies are not being used by the crates inside the project. If we compile with RUSTFLAGS=-Wunused-crate-dependencies cargo build --release --timings we get the following output:\n... warning: external crate `actix` unused in `lib1`: remove the dependency or add `use actix as _;` | = note: requested on the command line with `-W unused-crate-dependencies` warning: external crate `serde_json` unused in `lib1`: remove the dependency or add `use serde_json as _;` warning: external crate `tokio` unused in `lib1`: remove the dependency or add `use tokio as _;` warning: `lib1` (lib) generated 3 warnings By removing the unused dependencies reported by the warnings, we reduced the total compilation time a little:\nFinished `release` profile [optimized] target(s) in 23.85s It is not much, but by not compiling those dependencies, we gained around 1.x seconds! To keep our project clean, we can use this flag in our CI/CD pipeline to warn us when we forget to remove an old dependency.\nYou can find the modifications made in this section here.\nRemoving unnecessary derives Macros create valid Rust code that then has to be parsed, transformed, validated and optimized. It may happen that you need to derive some trait, not because is used by productive code but is used by test code. It does not make sense to process that code in release builds.\nA nice “trick” to avoid processing that code in release builds is to derive it behind a cargo feature and only activate that feature in the [dev-dependencies] section of the Cargo.toml. The Cargo.toml from lib1 was changed this way:\n[package] name = \u0026#34;lib1\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [dependencies] mockall = { workspace = true, optional = true } reqwest = { workspace = true } serde = { workspace = true } [features] tests = [\u0026#34;dep:mockall\u0026#34;] And we put behind the tests feature, all the code we do not need in production 3:\n#[cfg_attr(feature = \u0026#34;tests\u0026#34;, mockall::automock)] pub trait Trait1 { fn fn1(); fn fn2(a: u16) -\u0026gt; String; fn fn3(a: String) -\u0026gt; u16; } ... #[derive(Serialize, Default)] #[cfg_attr(feature = \u0026#34;tests\u0026#34;, derive(Deserialize, PartialEq, Eq, Debug))] pub struct Struct1 { pub f1: u8, pub f2: String, pub f3: HashMap\u0026lt;String, String\u0026gt;, pub f4: HashSet\u0026lt;String\u0026gt;, pub f5: Vec\u0026lt;String\u0026gt;, } ... #[derive(Deserialize, Default)] #[cfg_attr(feature = \u0026#34;tests\u0026#34;, derive(Serialize, PartialEq, Eq, Debug))] pub struct Struct9 { pub f1: u8, pub f2: String, pub f3: HashMap\u0026lt;String, String\u0026gt;, pub f4: HashSet\u0026lt;String\u0026gt;, pub f5: Vec\u0026lt;String\u0026gt;, } Activating the feature will work for both unit and integration tests. Here are the compilation times after introducing the flag:\nAnd the total time:\nFinished release profile [optimized] target(s) in 21.58s By reducing the code generated by the derives and automock macros, Rust have less code to translate to intermediate representation (light blue), code to generate (purple) and optimize. The time reduction was huge, from an average of 4.x seconds to an average of 0.3 seconds.\nThe take-home lesson here is: do not take the auto generation of code. If you don’t need it in the production build, do not compile it.\nYou can find the modifications made in this section here.\nDynamic Linking Until now, the code contained in lib1 is statically linked to all the binaries in our project. Instead of repeating the code in every binary, we can use dynamic linking to have lib1 as a shared object, allowing the binaries to use the code without the need of having it embedded.\nWith dynamic linking we will not only achieve faster compile times, we will also get smaller binaries and, if there’s a bug in the library, we can fix it and deploy the shared object without the need of modifying the binaries (as long as we use the same Rust version used to compile the binaries).\nTo activate dynamic linking, we need to add to the lib1\u0026rsquo;s Cargo.toml the following lines at the end:\n[lib] crate-type = [\u0026#34;dylib\u0026#34;] And compile ithe project t with: RUSTFLAGS=\u0026quot;-C prefer-dynamic\u0026quot; cargo build --release --timings. Here are the compilation times with dynamic linking:\nThe compilation times for lib1 increased 4, but for binaries times reduced from an average of 0.8x to an average of 0.3x! They were also reduced in size: from 3489 kB to 12 kB!\nls -l --block-size=KB ./target/release total 7238kB -rwxr-xr-x 2 nico nico 12kB Sep 16 14:43 bin1 -rwxr-xr-x 2 nico nico 12kB Sep 16 14:43 bin10 -rw-r--r-- 1 nico nico 1kB Sep 16 14:43 bin10.d -rwxr-xr-x 2 nico nico 12kB Sep 16 14:43 bin11 -rw-r--r-- 1 nico nico 1kB Sep 16 14:43 bin11.d -rwxr-xr-x 2 nico nico 12kB Sep 16 14:43 bin12 ... drwxr-xr-x 2 nico nico 5kB Sep 16 14:43 incremental -rw-r--r-- 1 nico nico 1kB Sep 16 14:43 liblib1.d -rwxr-xr-x 2 nico nico 6555kB Sep 16 14:43 liblib1.so The total time was\nFinished `release` profile [optimized] target(s) in 19.74s If we check the libraries needed for any of our binaries, we are going to see a dependency with liblib1.so. ldd outputs \u0026ldquo;not found\u0026rdquo; because the shared object is located in the target directory at the moment of running the command and not in the usual paths where shared objects can be found (/lib, /usr/lib , /usr/local/lib) or in any of the paths listed in the LD_LIBRARY_PATH environment variable.\n$ ldd ./target/release/bin1 linux-vdso.so.1 (0x00007ffe573aa000) liblib1.so =\u0026gt; not found libstd-52417a9a08ba8fb9.so =\u0026gt; not found libgcc_s.so.1 =\u0026gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fc19594a000) libc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc195769000) /lib64/ld-linux-x86-64.so.2 (0x00007fc195986000) You can find the modifications made in this section here.\nCache dependencies Most of the total compilation time was taken by the the project\u0026rsquo;s dependencies. In this section we are going to explore two ways those dependencies can be cached so we avoid recompiling them every time we build it. This is specially useful in a continuous integration/deployment environment, where we are constantly compiling the project but the dependencies rarely change.\nsccache sccache is a tool developed by Mozilla. It can be used with several compilers, not only rustc. It works as a wrapper of the compiler, chaching compiled things locally on disk and avoiding recompiling them if possible.\nTo install it, we can run:\n$ cargo install sccache Then, we can use it by wrapping the rustc compiler with the RUSTC_WRAPPER environment variable:\n$ RUSTC_WRAPPER=sccache RUSTFLAGS=\u0026#34;-C prefer-dynamic\u0026#34; cargo build --release --timings We compiled the project with the dynamic linking activated. The first compilation took around 23 seconds, 3.x seconds more than last compilation but, in the first one, sccache was caching the compiled dependencies. After running cargo clean and recompiling the project again we get:\nFinished `release` profile [optimized] target(s) in 6.54s So, we dropped from an average of 19.x seconds to an average of 6.5x seconds!\nCargo Chef cargo-chef is an awesome tool created by Luca Palmieri. It is designed to speed up compilation times when using containers to build the project. Basically, what it does under the hood is locate all the entry points of our workspace either for libs (lib.rs) or binaries (main.rs), remove all the code from them, leave some trivial code like\n// main.rs fn main() {} and compile the project. In other words, it avoids compiling the source code from the project. It just compiles the dependencies to cache them. In future compilations, the dependencies will be already cached, so only the project’s business logic will be compiled.\nAs stated in the official documentation and in a warning if you try to use it locally, this is designed to be used with containers because it leverages on the Docker\u0026rsquo;s layer cache mechanism to work. It is not recommended using it to compile the project locally.\nFor demonstration purposes, I modified the Dockerfile suggested in the official cargo chef documentation:\nFROM lukemathwalker/cargo-chef:latest-rust-1 AS chef WORKDIR /app FROM chef AS planner COPY . . RUN cargo chef prepare --recipe-path recipe.json FROM chef AS builder COPY --from=planner /app/recipe.json recipe.json # Build dependencies - this is the caching Docker layer! RUN CARGO_TARGET_DIR=/app/cache RUSTFLAGS=\u0026#34;-C prefer-dynamic\u0026#34; cargo chef cook --release --workspace --recipe-path recipe.json COPY . . ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;] The image produced from this Dockerfile will contain all the project dependencies already cached in /app/cache directory. It is very important to use cargo chef with exactly the same configuration you are going to use to compile the project. Since we are using the dynamic linking branch for the demonstration, we must include the RUSTFLAGS=\u0026quot;-C prefer-dynamic\u0026quot; flag.\nHere are the steps I followed:\nBuild the image: docker build --tag chef . Enter the container: docker run -it chef Compile the project: CARGO_TARGET_DIR=/app/cache RUSTFLAGS=\u0026quot;-C prefer-dynamic\u0026quot; cargo build --release --workspace. The total compilation time is:\nFinished `release` profile [optimized] target(s) in 2.64s We’ve just compiled the whole project in 2.64s! This is a massive time reduction!\nSummary We started our compile time reduction journey with static linked binaries with a size of 3489kB and a total compilation time of 25.x seconds and we finished it with dynamically linked binaries with a size of 12kB and a total compilation time of 2.x seconds:\nModification Total time % Time reduction from original Original codebase 25.3s 0% Remove unused dependencies 23.85s 5.73% Remove unnecesary derives 21.58s 14.70% Dynamic Linking 19.74s 21.98% Dynamic Linking + sccache 6.54s 75.15% Dynamic Linking + cargo chef 2.64s 89.57% It is important to remember that all the steps include the modifications from the previous steps, with the exception of the caches, that use the dynamic linking branch but sccache and cargo chef are used separately.\nConclusion Sometimes when we are working on projects, deadlines are tight, product team need to release new features and we need to choose wisely on what we spend our time. If we are lucky enough to be in a team that saves time to work on technical debt, we should really use that oportunity to make the structural changes needed in the project to reduce the compilation times. This may sound obvious but not everyone agrees on what is important to solve first.\nWhen projects are small, compilation times are usually small or tolerable, so we don’t pay much attention. As it grows, compilation times may become a real bottleneck for development (imagine that deploying a new version to a dev environment takes an hour).\nTaking care of the compilation will save the whole team a lot of time and headaches, enabling everyone to develop, test and deploy faster.\nResources Learn how to setup dynamically loadable plugins for your Rust app Rust’s official Linkage page Linking Rust crates series Minimizing Compile Times Speeding up incremental Rust compilation with dylibs Build cache There’s a mode that we can use to avoid recompiling the library to match the Rust version we are currently using: cdylib . This mode will produce a dynamic linked library that can be used by other programming languages (and of course, also by Rust). The code compiled with this configuration will follow the C ABI (ordering, size, alignment of fields, etc…) enabling the possibility of directly linking the shared library with a C/C++ program or creating the bindings to use it in another language. The problem with this configuration and Rust is that using the shared object is not straightforward thanks to the C ABI. In another article I will explore this way and show how you can use a Rust library in other languages.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCompilations are quite fast because there\u0026rsquo;s not much code. It is enough to show the compilation times improvements.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYou may ask yourself why I used a feature flag and #[cfg_attr(feature = \u0026quot;tests\u0026quot;, ...)] instead of plain #[cfg(test)]. With #[cfg(test)], only the current crate would be able to see things under that configuration, or in other words, we would not be able to use the things behind that configuration in the unit and integration tests of the binaries.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI am not sure why the codegen section (purple) disappeared from the graph and why it took almost the double to compile it. I made the modifications described here in some real world projects and the timings certainly did not doubled for the library crates.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://nicoan.github.io/posts/accelerating_compile_times/","summary":"Having a language that does a lot of checks at compile time is not free, it will impact compilation times. Luckily there are some things we can do to speed things up: Dynamic linking, be careful with code generation and caching dependencies.\nDynamic linking is a somewhat difficult thing to achieve in Rust but not impossible. The main reason is that at the time of writing this (Sept-Oct 2024) Rust does not have its own stable ABI and it must rely on the C binary representation (if we want to inter-operate with other languages or other Rust versions).","title":"Accelerating Rust compilation times: Dynamic linking, code generation and cache"},{"content":"Now it is time to talk about references and borrowing. To understand this topic, first check out this post where I talk about ownership and move semantics. As we have seen in the named article, the way Rust manages memory allocations is rather unique. This is also true when we talk about referencing some place in the memory, something that can be achieved in C with pointers.\nGDB In this post I am going to explore what is happening in memory using the GNU Debugger (gdb) with the special command rust-gdb:\nWhat is a reference in Rust? A reference is a value that points to data in memory. Although it is similar to a classic pointer there is a crucial difference between the two: a reference is guaranteed to always point to a memory address that contains a valid piece of data whereas pointers are not¹. The checks performed to guarantee that a reference is always valid is done at compile time.\nConsider the following code:\n1 2 3 4 5 6 7 8 9 fn main() { // Create a new value, with s1 as owner let s1 = String::from(\u0026#34;hello world!\u0026#34;); // Create a reference of s1 let s2 = \u0026amp;s1; // Print the s2 value println!(\u0026#34;{}\u0026#34;, s2); } This code compiles and runs correctly. What happens in memory? Let’s check it out with GDB!\nBreakpoint 1, references_and_borrowing::main () at src/main.rs:3 3 let s1 = String::from(\u0026#34;hello world!\u0026#34;); (gdb) n 5 let s2 = \u0026amp;s1; (gdb) n 8 println!(\u0026#34;{}\u0026#34;, s2); At this point, the String s1 is initialized with the text \u0026quot;hello world! and the s1\u0026rsquo;s reference named s2 is set. Let\u0026rsquo;s check the stack:\n1 2 3 4 5 6 7 8 9 10 0x7fffffffd920: 56 217 255 255 255 127 0 0 0x7fffffffd928: 112 251 90 85 85 85 0 0 0x7fffffffd930: 32 208 255 247 255 127 0 0 0x7fffffffd938: 160 251 90 85 85 85 0 0 0x7fffffffd940: 12 0 0 0 0 0 0 0 0x7fffffffd948: 12 0 0 0 0 0 0 0 0x7fffffffd950: 56 217 255 255 255 127 0 0 0x7fffffffd958: 128 167 218 247 255 127 0 0 0x7fffffffd960: 0 0 0 0 0 0 0 0 0x7fffffffd968: 0 0 0 0 0 0 0 0 The lines 4 to 6 is the representation of s1 in the stack: 0x7fffffffd938 is ptr, 0x7fffffffd940 is len and 0x7fffffffd948 is capacity. The reference to s1 is located at 0x7fffffffd950. Let\u0026rsquo;s print the address value in hexadecimal:\n(gdb) x/xg 0x7fffffffd950 0x7fffffffd950: 0x00007fffffffd938 As we can see, the value contained in the address 0x7fffffffd950 is 0x00007fffffffd938², the beginning of the s1\u0026rsquo;s stack representation!\n¹ An invalid memory region refers to a region that was not assigned to our process or memory that was valid at some point of the program execution but then was freed. ² Zeroes are trimmed for legibility when printed as a memory address by GDB.\nThe two rules of references As everything in Rust, references have their own set of rules.\nReferences are always valid. At any given time we either have any number of immutable references or one mutable reference. References are always valid There\u0026rsquo;s no way of testing this rule at runtime (or at least I don\u0026rsquo;t know one). As I stated earlier in this post, references are guaranteed to always be valid and this validation is done at compile time.\nAt any given time we either have any number of immutable references or one mutable reference At first glance, this rule feels like an unnecessary limitation but thanks to it we are able to catch hidden bugs in our code because data races are avoided at compile time.\nA classic example is the one where we have n mutable references of the same piece of numeric data that represents a counter, all in different threads. The only thing the threads do is increment the counter. References by themselves do not have a synchronization mechanism. This is the concurrent counter problem, here\u0026rsquo;s the whole explanation and an example code in Java. This can\u0026rsquo;t happen in Rust (code won\u0026rsquo;t compile) since we need some kind of synchronization mechanism to mutate the same piece of data in different threads.\nThis is not the only problem this rule keeps us away from! In fact, we don\u0026rsquo;t even need concurrency, it can avoid bugs in simpler situations. Consider the following code in python:\n1 2 3 4 5 6 7 8 def insert_even_zeros(vec): for (n,i) in enumerate(vec): if n % 2 == 0: vec.insert(i, 0) vec = list(range(1,7)) # [1, 2, 3, 4, 5, 6] print(vec) What we are trying to do here is to insert a 0 at the index of a value, if the value is an even number. The expected result for the input [1, 2, 3, 4, 5, 6] is [1, 0, 2, 3, 0, 4, 5, 0, 6] but if we run it, we get [1, 0, 0, 0, 0, 0, 0, 2, 3, 4, 5, 6]. What is happening? The source of the problem resides in the fact that we are mutating the vector while iterating it:\nWe start at index 0 where the value 1 is located, since 1 is not even we continue to index 1. At index 1 we find value 2. It is even so we insert a 0 at index 1. Now the array is: [1, 0, 2, 3, 4, 5, 6]. We continue to index 2. At index 2 we find the value 2 again, because it was moved from its original position in the previous iteration. It is even so we insert a 0 at index 2. Now the array is: [1, 0, 0, 2, 3, 4, 5, 6]. This process is repeated 4 more times since the array length is 6 and how many iterations are going to be executed is calculated at the beginning of the for statement. This is known as the iterator invalidation problem.\nWhat happens in Rust?\n1 2 3 4 5 6 7 8 9 10 11 12 fn insert_even_zeros(vec: \u0026amp;mut Vec\u0026lt;u8\u0026gt;) { for (i, n) in vec.iter().enumerate() { if n % 2 == 0 { vec.insert(i, 0); } } } fn main() { let mut v: Vec\u0026lt;u8\u0026gt; = (1..=6).collect(); // [1, 2, 3, 4, 5, 6] insert_even_zeros(\u0026amp;mut v); } We get a compilation error that enforces the rule!\nerror[E0502]: cannot borrow `*vec` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:4:13 | 2 | for (i, n) in vec.iter().enumerate() { | ---------------------- | | | immutable borrow occurs here | immutable borrow later used here 3 | if n % 2 == 0 { 4 | vec.insert(i, 0); | ^^^^^^^^^^^^^^^^ mutable borrow occurs here For more information about this error, try `rustc --explain E0502`. Where are the mutable and immutable references? In the vector\u0026rsquo;s function signatures:\n.iter() takes an immutable reference of the vector (\u0026amp;self): pub fn iter(\u0026amp;self) -\u0026gt; Iter\u0026lt;\u0026#39;_, T\u0026gt; .insert() takes a mutable reference of the vector (\u0026amp;mut self): pub fn insert(\u0026amp;mut self, index: usize, element: T) Does this mean that there\u0026rsquo;s no way of modifying a vector in Rust while iterating it? No! You can do it:\n1 2 3 4 5 6 7 8 9 10 11 12 fn main() { let mut v: Vec\u0026lt;u8\u0026gt; = (1..=6).collect(); let mut i: usize = 0; let v_len = v.len(); while i \u0026lt; v_len { if v[i] % 2 == 0 { v.insert(i, 0); } i += 1 } } We also have two references, one immutable (len function) and one mutable (insert function). Why does it work? Because the scope of the immutable reference that is in len ends right after it the function is used (the scope of a reference begins at its creation and extends until the last time the reference is used).\nNotice that the error message we got with the for loop says \u0026ldquo;immutable borrow occurs here\u0026rdquo; and \u0026ldquo;immutable borrow later used here\u0026rdquo;. Both errors come from the same place, the iter() function, where the immutable reference is used.\nDoes it make sense for a programming language to have these kinds of rules if it is possible to write code to circumvent them? Yes! The way the last code is written is rather \u0026ldquo;unnatural\u0026rdquo;. Most of the time Rust will catch bugs at compile time thanks to these rules.\nBorrowing There are times when you don\u0026rsquo;t want a specific scope to lose ownership of a value. There could be several reasons for that, for example, you need to reuse the value. Consider the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 fn hello(s: String) { println!(\u0026#34;hello {s}.\u0026#34;); } fn bye(s: String) { println!(\u0026#34;bye {s}.\u0026#34;); } fn main() { let s = String::from(\u0026#34;fellow blog reader\u0026#34;); hello(s); bye(s); } This code won\u0026rsquo;t compile:\nerror[E0382]: use of moved value: `s` --\u0026gt; src/main.rs:12:9 | 10 | let s = String::from(\u0026#34;fellow blog reader\u0026#34;); | - move occurs because `s` has type `String`, which does not implement the `Copy` trait 11 | hello(s); | - value moved here 12 | bye(s); | ^ value used here after move | note: consider changing this parameter type in function `hello` to borrow instead if owning the value isn\u0026#39;t necessary --\u0026gt; src/main.rs:1:13 | 1 | fn hello(s: String) { | ----- ^^^^^^ this parameter takes ownership of the value | | | in this function help: consider cloning the value if the performance cost is acceptable | 11 | hello(s.clone()); | ++++++++ Here we have a similar situation as we had here. As the compiler error says, we are moving s into hello, so when we try to use it in bye we get the \u0026ldquo;use after move\u0026rdquo; error. How can we solve this?\nSolution 1: Duplicating the value We can do as the compiler says, and clone the value. This way, both functions get a separate copy of the value that they can own:\n1 2 3 4 5 6 7 8 9 10 11 12 13 fn hello(s: String) { println!(\u0026#34;hello {s}.\u0026#34;); } fn bye(s: String) { println!(\u0026#34;bye {s}.\u0026#34;); } fn main() { let s = String::from(\u0026#34;fellow blog reader\u0026#34;); hello(s.clone()); bye(s); } This works! the code compiles and executes without a warning. Is this a good solution? No.\nWe don\u0026rsquo;t really need to duplicate s since we are only reading it to print it out. This solution does a lot of extra work by duplicating s\u0026rsquo;s value in memory.\nSolution 2: Returning the ownership back to the caller Instead of duplicating s\u0026rsquo;s value, we can return the ownership to the caller, so it can use it again:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 fn hello(s: String) -\u0026gt; String { println!(\u0026#34;hello {s}.\u0026#34;); s } fn bye(s: String) { println!(\u0026#34;bye {s}.\u0026#34;); } fn main() { let s = String::from(\u0026#34;fellow blog reader\u0026#34;); let s2 = hello(s); bye(s2); } This also works! the code compiles and executes without a warning. Is this a good solution? Also no.\nPassing ownership back and forth functions is not a very comfortable and idiomatic way of doing things. On top of that, the function signatures are not semantically accurate. The signature of hello suggests that we pass an String value and returns back another String value. By just looking at it, it is hard to understand what the function intends to do and it does not make sense to return anything if the only objective of the function is only to print something.\nSolution 3: Borrowing We need to keep the ownership of s in the scope of the main function, we don\u0026rsquo;t want to duplicate values and we don\u0026rsquo;t want to move the values back and forth either. What can we do? use a reference!\n1 2 3 4 5 6 7 8 9 10 11 12 13 fn hello(s: \u0026amp;String) { println!(\u0026#34;hello {s}.\u0026#34;); } fn bye(s: \u0026amp;String) { println!(\u0026#34;bye {s}.\u0026#34;); } fn main() { let s = String::from(\u0026#34;fellow blog reader\u0026#34;); hello(\u0026amp;s); bye(\u0026amp;s); } The code compiles and executes without a warning. Is this a good solution? Yes.\nGiven that we only need to read the value, we don\u0026rsquo;t want to move it or duplicate it, using a reference is the best solution. Also, it is more idiomatic and semantically correct. By looking at the function\u0026rsquo;s signatures we know that they do not need to own any value and they will not return any result from the operation they are performing.\nLet\u0026rsquo;s now check what is happening in the memory with GDB:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Breakpoint 1, references_and_borrowing::main () at src/main.rs:10 10 let s = String::from(\u0026#34;fellow blog reader\u0026#34;); (gdb) n 11 hello(\u0026amp;s); (gdb) x/80ub $sp 0x7fffffffd970: 2 0 0 0 0 0 0 0 0x7fffffffd978: 128 217 255 255 255 127 0 0 0x7fffffffd980: 160 251 90 85 85 85 0 0 0x7fffffffd988: 18 0 0 0 0 0 0 0 0x7fffffffd990: 18 0 0 0 0 0 0 0 0x7fffffffd998: 48 251 90 85 85 85 0 0 0x7fffffffd9a0: 1 0 0 0 0 0 0 0 0x7fffffffd9a8: 59 216 85 85 85 85 0 0 0x7fffffffd9b0: 0 240 127 255 255 127 0 0 0x7fffffffd9b8: 48 251 90 85 85 85 0 0 Looks like our String representation in the stack starts at 0x7fffffffd980. Let\u0026rsquo;s confirm it.\n(gdb) x/xg 0x7fffffffd980 0x7fffffffd980: 0x00005555555afba0 (gdb) x/18c 0x00005555555afba0 0x5555555afba0: 102 \u0026#39;f\u0026#39; 101 \u0026#39;e\u0026#39; 108 \u0026#39;l\u0026#39; 108 \u0026#39;l\u0026#39; 111 \u0026#39;o\u0026#39; 119 \u0026#39;w\u0026#39; 32 \u0026#39; \u0026#39; 98 \u0026#39;b\u0026#39; 0x5555555afba8: 108 \u0026#39;l\u0026#39; 111 \u0026#39;o\u0026#39; 103 \u0026#39;g\u0026#39; 32 \u0026#39; \u0026#39; 114 \u0026#39;r\u0026#39; 101 \u0026#39;e\u0026#39; 97 \u0026#39;a\u0026#39; 100 \u0026#39;d\u0026#39; 0x5555555afbb0: 101 \u0026#39;e\u0026#39; 114 \u0026#39;r\u0026#39; Excellent, now let\u0026rsquo;s continue with the program execution and check what\u0026rsquo;s in hello function\u0026rsquo;s stack:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Breakpoint 2, references_and_borrowing::hello (s=0x7fffffffd980) at src/main.rs:2 2 println!(\u0026#34;hello {s}.\u0026#34;); (gdb) x/80ub $sp 0x7fffffffd900: 128 217 255 255 255 127 0 0 0x7fffffffd908: 140 201 85 85 85 85 0 0 0x7fffffffd910: 32 208 255 247 255 127 0 0 0x7fffffffd918: 128 217 255 255 255 127 0 0 0x7fffffffd920: 128 217 255 255 255 127 0 0 0x7fffffffd928: 154 177 222 247 255 127 0 0 0x7fffffffd930: 160 251 90 85 85 85 0 0 0x7fffffffd938: 18 0 0 0 0 0 0 0 0x7fffffffd940: 18 0 0 0 0 0 0 0 0x7fffffffd948: 213 192 89 85 85 85 0 0 (gdb) x/xg 0x7fffffffd920 0x7fffffffd920: 0x00007fffffffd980 At 0x7fffffffd920 found a pointer pointing to s in main\u0026rsquo;s stack (0x7fffffffd920: 0x00007fffffffd980)! We can confirm that the whole representation still belongs to main\u0026rsquo;s scope and, in hello and bye functions, we are just referencing it. smemory will be freed once main finishes.\nThere\u0026rsquo;s no need to change the scope to borrow a value: the code used in the previous section, is just a slight modification of an example used in a previous post that did not compile. We fixed it by borrowing s1\u0026rsquo;s value to s2.\nConclusion Sometimes we have a hard time fighting the Rust compiler because it usually fails with errors that do not exist in other programming languages. Those errors feel arbitrary but, as we have seen in this post, they are there to protect us. It can take some time to wrap your head around them.\nThe more you code in Rust, the less you fight with the compiler and you end up with more performant and more secure programs. Also, a lot of errors are caught at compile time, saving us a lot of precious debugging time.\nThis post concludes a series of post about how Rust handles memory the internals of it:\nStack and Heap Rust ownership and move semantics from the inside Rust references and borrowing from the inside ","permalink":"https://nicoan.github.io/posts/references_and_borrowing/","summary":"Now it is time to talk about references and borrowing. To understand this topic, first check out this post where I talk about ownership and move semantics. As we have seen in the named article, the way Rust manages memory allocations is rather unique. This is also true when we talk about referencing some place in the memory, something that can be achieved in C with pointers.\nGDB In this post I am going to explore what is happening in memory using the GNU Debugger (gdb) with the special command rust-gdb:","title":"Rust references and borrowing from the inside"},{"content":"Ownership and move semantics is one of the things that makes Rust unique. To understand this topic, you need to understand what Stack and Heap are at a basic level. I wrote a post about that! You can check it out if you need a refresher on those concepts. It is a little bit hard to get used to this feature because it forces you to think about stuff that you didn\u0026rsquo;t have to worry about in other languages. Enough introduction, let\u0026rsquo;s cut to the chase!\nThe three rules of ownership There are three rules that governs the ownership system:\nEvery initialized value has an owner: Every initialized value has a variable that is its owner.¹ There is only one owner per value: You can\u0026rsquo;t have two or more variables that owns the same value in memory. You can\u0026rsquo;t share ownership between variables.² If a variable\u0026rsquo;s scope ends, its value gets freed: When a scope ends, all values owned by variables contained in that scope get automatically freed. ¹ But not every variable owns a value, they may just hold a reference. I\u0026rsquo;ll talk about this in the \u0026ldquo;References and Borrowing\u0026rdquo; article. ² Actually you can have more than one owner in safe Rust. You have to use special structures, such as Rc (multiple owners do not own the value directly though).\nLet\u0026rsquo;s test the rules! But before that, a little reminder of how the String type is represented in memory:\nwhere:\nptr: A pointer to the first direction of the Heap containing the string itself (in this case hello). len: How much memory, in bytes, the contents of the string is currently using. capacity: The total amount of memory, in bytes, allocated for that string. GDB In this post, I am going to explore what is happening in memory using the GNU Debugger (gdb) with the special command rust-gdb:\n$ rust-gdb ./target/debug/move_semantics I am going to use the x command a lot to explore the stack and the $sp value (refers to the Stack Pointer).\nRule 1: Every initialized value has an owner. Consider the following code:\n1 2 3 4 5 6 7 8 9 fn hello_world() -\u0026gt; u32 { String::from(\u0026#34;hello! I am a free initialized String!\u0026#34;); println!(\u0026#34;{}\u0026#34;, 42); 42 } fn main() { hello_world(); } In the hello_world function, we have an initialized String value that is free (not assigned to a variable). Did Rust initialize the value in memory or just ignore it? We can\u0026rsquo;t use it so\u0026hellip; Why would Rust save it? Let\u0026rsquo;s check what happens! When we compile this code we get the following warning:\nwarning: unused return value of `from` that must be used --\u0026gt; src/main.rs:2:5 | 2 | String::from(\u0026#34;hello! I am a free initialized String!\u0026#34;); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: `#[warn(unused_must_use)]` on by default Rust warns us that we must use the returned value of the String::from function, otherwise, we can\u0026rsquo;t access it in any way. What happens in memory? Let\u0026rsquo;s check it out with GDB!\nFirst, we set a breakpoint at the beginning of the hello_world function and execute the String initialization:\nBreakpoint 1, move_semantics::hello_world () at src/main.rs:2 2 String::from(\u0026#34;hello! I am a free initialized String!\u0026#34;); (gdb) n 3 println!(\u0026#34;{}\u0026#34;, 42); At this point, the String is initialized, but it isn\u0026rsquo;t assigned to a variable. So, it has no owner! Let\u0026rsquo;s check the stack:\n1 2 3 4 5 6 7 8 9 10 11 (gdb) x/80ub $sp 0x7fffffffd980: 0 240 127 255 255 127 0 0 0x7fffffffd988: 61 60 87 85 85 85 0 0 0x7fffffffd990: 16 90 90 85 85 85 0 0 0x7fffffffd998: 38 0 0 0 0 0 0 0 0x7fffffffd9a0: 38 0 0 0 0 0 0 0 0x7fffffffd9a8: 2 0 0 0 0 0 0 0 0x7fffffffd9b0: 48 0 0 0 0 0 0 0 0x7fffffffd9b8: 96 255 255 255 255 255 255 255 0x7fffffffd9c0: 0 240 127 255 255 127 0 0 0x7fffffffd9c8: 5 0 0 0 0 0 0 0 It seems that the String value is there, lines 4 to 6 looks like our initialized value: memory addresses 0x7fffffffd998 and 0x7fffffffd9a0 (lines 5 and 6) have a 38 stored, and the string happens to have 38 characters. 0x7fffffffd990 (line 4) must be the Heap address where the actual text is allocated! Let\u0026rsquo;s see what\u0026rsquo;s inside that memory address.\nFirst, print the address as hexa:\n(gdb) x/xg 0x7fffffffd990 0x7fffffffd990:\t0x00005555555a5a10 Then, explore what\u0026rsquo;s inside that address!\n1 2 3 4 5 6 (gdb) x/38cb 0x00005555555a5a10 0x5555555a5a10: 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0x5555555a5a18: 16 \u0026#39;\\020\u0026#39; 80 \u0026#39;P\u0026#39; 90 \u0026#39;Z\u0026#39; 85 \u0026#39;U\u0026#39; 85 \u0026#39;U\u0026#39; 85 \u0026#39;U\u0026#39; 0 \u0026#39;\\000\u0026#39; 0 \u0026#39;\\000\u0026#39; 0x5555555a5a20: 101 \u0026#39;e\u0026#39; 101 \u0026#39;e\u0026#39; 32 \u0026#39; \u0026#39; 105 \u0026#39;i\u0026#39; 110 \u0026#39;n\u0026#39; 105 \u0026#39;i\u0026#39; 116 \u0026#39;t\u0026#39; 105 \u0026#39;i\u0026#39; 0x5555555a5a28: 97 \u0026#39;a\u0026#39; 108 \u0026#39;l\u0026#39; 105 \u0026#39;i\u0026#39; 122 \u0026#39;z\u0026#39; 101 \u0026#39;e\u0026#39; 100 \u0026#39;d\u0026#39; 32 \u0026#39; \u0026#39; 83 \u0026#39;S\u0026#39; 0x5555555a5a30: 116 \u0026#39;t\u0026#39; 114 \u0026#39;r\u0026#39; 105 \u0026#39;i\u0026#39; 110 \u0026#39;n\u0026#39; 103 \u0026#39;g\u0026#39; 33 \u0026#39;!\u0026#39; Our String is mostly there! But, it appears that the beginning of it was overwritten. It\u0026rsquo;s ok, that value isn\u0026rsquo;t owned by any variable; we can\u0026rsquo;t access it. So, it doesn\u0026rsquo;t matter what happens to it.\nNOTE: This memory exploration was done using a debug build. I am not really sure what happens if this code was compiled in release mode. I believe that Rust does not initialize the value as an optimization, because it is not used.\nRule 2: There\u0026rsquo;s only one owner per value Consider the following code:\n1 2 3 4 5 6 7 8 fn main() { // Create a new value, with s1 as owner let s1 = String::from(\u0026#34;hello world!\u0026#34;); // Move ownership from s1 to s2 let s2 = s1; // Oops! compiler error, the value has been moved! println!(\u0026#34;{}\u0026#34;, s1); } When we try to compile this, we get:\nerror[E0382]: borrow of moved value: `s1` --\u0026gt; src/main.rs:7:20 | 3 | let s1 = String::from(\u0026#34;hello world!\u0026#34;); | -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait 4 | // Move ownership from s1 to s2 5 | let s2 = s1; | -- value moved here 6 | // Oops! compiler error, the value has been moved! 7 | println!(\u0026#34;{}\u0026#34;, s1); | ^^ value borrowed here after move What is happening here is that the ownership of the String \u0026quot;hello world!\u0026quot; is transferred from s1 to s2. Because of that, the compiler invalidates the access to s1.\nThe value was moved because the type String does not implement the Copy trait. This is used on types that can be fully allocated in the stack and can be duplicated by simply copying bits without much overload (duplicating data in the Heap is much more complicated). When a type implements the Copy trait, instead of having \u0026ldquo;move semantics\u0026rdquo; it has \u0026ldquo;copy semantics\u0026rdquo;. This is usually the case for primitive types:\n1 2 3 4 5 6 fn main() { let n1 = 42; let n2 = n1; println!(\u0026#34;{}\u0026#34;, n1); println!(\u0026#34;{} {}\u0026#34;, n1, n2); } If we run this code\u0026hellip;\ncargo run Compiling move_semantics v0.1.0 (/home/rust/blog) Finished dev [unoptimized + debuginfo] target(s) in 0.30s Running `target/debug/move_semantics` 42 42 42 compiles! Because the value 42 is copied!\nRule 3: If a variable\u0026rsquo;s scope ends its value gets freed Consider the following code:\n1 2 3 4 5 6 7 8 fn main() { { // Create a new value with s1 as owner let s1 = String::from(\u0026#34;hello world!\u0026#34;); } // s1 gets dropped here! since is the end of the scope println!(\u0026#34;Checking drop with gdb!\u0026#34;); } s1 allocation will have been freed when we reach line 7. This is because the curly braces at the beginning of the main function creates a new scope. Once the code reaches the end of it, all the variables that it contained get dropped. Let\u0026rsquo;s check it out in GDB:\nOn line 4, we can find s1 in the locals variables of the scope:\nBreakpoint 1, move_semantics::main () at src/main.rs:4 4\tprintln!(\u0026#34;{}\u0026#34;, s1); (gdb) info locals s1 = \u0026#34;hello world!\u0026#34; Let\u0026rsquo;s check where the Heap allocation of s1 is and what value it contains (remember that the first field of the Stack representation is the pointer to the Heap):\n(gdb) p \u0026amp;s1 $1 = (*mut alloc::string::String) 0x7fffffffd960 (gdb) x/xg 0x7fffffffd960 0x7fffffffd960:\t0x00005555555a5ad0 (gdb) x/12c 0x00005555555a5ad0 0x5555555a5ad0:\t104 \u0026#39;h\u0026#39;\t101 \u0026#39;e\u0026#39;\t108 \u0026#39;l\u0026#39;\t108 \u0026#39;l\u0026#39;\t111 \u0026#39;o\u0026#39;\t32 \u0026#39; \u0026#39;\t119 \u0026#39;w\u0026#39;\t111 \u0026#39;o\u0026#39; 0x5555555a5ad8:\t114 \u0026#39;r\u0026#39;\t108 \u0026#39;l\u0026#39;\t100 \u0026#39;d\u0026#39;\t33 \u0026#39;!\u0026#39; But when the scope finishes\u0026hellip;\n7\tprintln!(\u0026#34;Checking drop with gdb!\u0026#34;); (gdb) info locals No locals. (gdb) x/12c 0x00005555555a5ad0 0x5555555a5ad0:\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39;\t0 \u0026#39;\\000\u0026#39; 0x5555555a5ad8:\t16 \u0026#39;\\020\u0026#39;\t80 \u0026#39;P\u0026#39;\t90 \u0026#39;Z\u0026#39;\t85 \u0026#39;U\u0026#39; All the locals variables were dropped and the memory occupied by them freed! That part of the Heap is now filled with something else (probably garbage).\nMoving a value: What happens under the hood? Consider the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 fn move_stack_example() { // Create a new String value let s1 = String::from(\u0026#34;hello world!\u0026#34;); // Move it from s1 to s2 (s2 takes ownership) let s2 = s1; println!(\u0026#34;{}\u0026#34;, s2); } fn main() { move_stack_example(); } When we move a value, it does not dissapears from the memory, instead, whatever is in the stack that belongs to the moved value gets duplicated and the compiler just forbids us from accessing the old variable ever again.\nLet\u0026rsquo;s verify what I just said with GDB. We are going to examine the stack frame of the move_stack_example function. First of all, let\u0026rsquo;s check the locals variables:\n(gdb) info locals s2 = \u0026#34;hello world!\u0026#34; s1 = \u0026#34;hello world!\u0026#34; Whoa! Looks like s1 and s2 have the same value! Actually they are pointing to the same value. Let\u0026rsquo;s now see what the addresses of s1 and s2 are:\n(gdb) p \u0026amp;s1 $1 = (*mut alloc::string::String) 0x7fffffffdb08 (gdb) p \u0026amp;s2 $2 = (*mut alloc::string::String) 0x7fffffffdb20 Great! Now, we know that s1\u0026rsquo;s stack representation starts at 0x7fffffffdb08 and s2\u0026rsquo;s starts at 0x7fffffffdb20. Let\u0026rsquo;s now see the contents of the stack frame:\n1 2 3 4 5 6 7 8 9 10 11 (gdb) x/80bu $sp 0x7fffffffdaf0:\t112\t171\t217\t247\t255\t127\t0\t0 0x7fffffffdaf8:\t7\t125\t221\t247\t255\t127\t0\t0 0x7fffffffdb00:\t2\t0\t0\t0\t0\t0\t0\t0 0x7fffffffdb08:\t208\t90\t90\t85\t85\t85\t0\t0 0x7fffffffdb10:\t12\t0\t0\t0\t0\t0\t0\t0 0x7fffffffdb18:\t12\t0\t0\t0\t0\t0\t0\t0 0x7fffffffdb20:\t208\t90\t90\t85\t85\t85\t0\t0 0x7fffffffdb28:\t12\t0\t0\t0\t0\t0\t0\t0 0x7fffffffdb30:\t12\t0\t0\t0\t0\t0\t0\t0 0x7fffffffdb38:\t0\t0\t0\t0\t0\t0\t0\t0 What do we have at s1 and s2 addresses? Let\u0026rsquo;s check it out!:\nptr: For s1 this value is at 0x7fffffffdb08. For s2 this value is at 0x7fffffffdb20. len: For s1 this value is at 0x7fffffffdb10. For s2 this value is at 0x7fffffffdb28. capacity: For s1 this value is at 0x7fffffffdb18. For s2 this value is at 0x7fffffffdb30. As you can see, both ptr values are the same, meaning that both variables are pointing to the same data in the Heap. Let\u0026rsquo;s print them in hexadecimal to get the correct format to explore it:\n(gdb) x/xg 0x7fffffffdb08 0x7fffffffdb08: 0x00005555555a5ad0 (gdb) x/xg 0x7fffffffdb20 0x7fffffffdb20: 0x00005555555a5ad0 So, the ptr value is 0x00005555555a5ad0! Now, take a look at the contents of that address in the Heap:\n(gdb) x/12c 0x00005555555a5ad0 0x5555555a5ad0:\t104 \u0026#39;h\u0026#39;\t101 \u0026#39;e\u0026#39;\t108 \u0026#39;l\u0026#39;\t108 \u0026#39;l\u0026#39;\t111 \u0026#39;o\u0026#39;\t32 \u0026#39; \u0026#39;\t119 \u0026#39;w\u0026#39;\t111 \u0026#39;o\u0026#39; 0x5555555a5ad8:\t114 \u0026#39;r\u0026#39;\t108 \u0026#39;l\u0026#39;\t100 \u0026#39;d\u0026#39;\t33 \u0026#39;!\u0026#39; The hello world! string is there!\nConclusion It can take some time to get used to working with ownership and move semantics, but, in my opinion, that is well invested time. Manually managing memory (by allocating and freeing it) is not an easy task and can create several bugs. With Rust\u0026rsquo;s approach, those bugs are caught at compile time, so they can never happen!\nIf you want to read more about this topic, check out the Rust book.\n","permalink":"https://nicoan.github.io/posts/move_semantics/","summary":"Ownership and move semantics is one of the things that makes Rust unique. To understand this topic, you need to understand what Stack and Heap are at a basic level. I wrote a post about that! You can check it out if you need a refresher on those concepts. It is a little bit hard to get used to this feature because it forces you to think about stuff that you didn\u0026rsquo;t have to worry about in other languages.","title":"Rust ownership and move semantics from the inside"},{"content":"Why write about Stack and Heap when there are already a lot of articles out there? I want to improve my writing skills so, I decided to write articles about things I find interesting. This article was supposed to be about how Rust manages memory through ownership. Then I thought \u0026ldquo;I should first write about Stack and Heap\u0026rdquo;. So, here we are).\nTo understand memory management first, we need to understand what the Stack and the Heap are. Stack and Heap are memory regions used by a process to store and read values. The memory of a running process can usually be divided in the following four regions:\nText: Here is where our program instructions live. Our compiled program is loaded and stored in this region of the memory. Data: All the global variables are stored in this region. Stack: A contiguous chunk of memory that stores local variables, arguments and return addresses of functions (we will go deeper on this in the next section). Every process\u0026rsquo; thread has its own Stack. Heap: Stores all the dynamically allocated memory. This region is shared among all threads of a process. Stack A process\u0026rsquo; Stack is an actual implementation of the Stack data structure. It is fixed in size; we can not ask the operating system for more memory. This size depends mostly on the OS. In modern Linux systems, the maximum Stack size is 8 MB (you can check yours with the command ulimit -s).\nInside the Stack Every time we call a function, a Stack frame (a chunk of contiguous memory containing all the information required by the recently called function) is created and placed on top of the Stack. And, every time a function ends, the Stack frame is popped from the Stack, automatically releasing all the memory used by it. Let\u0026rsquo;s see a minimal example on how the Stack is populated. Consider the following code:\nfn sum(a: i32, b: i32) -\u0026gt; i32 { let result = a + b; result } fn square_sum(a: i32, b: i32) -\u0026gt; i32 { let sum_result = sum(a, b); let pow_result = sum_result * sum_result; pow_result } fn main() { let n1 = 2; let n2 = 5; let pow_result = square_sum(n1, n2); println!(\u0026#34;Result: {}\u0026#34;, pow_result); } The following diagram represents what happens with the Stack when the program is executed:\nAt the beginning, a Stack frame for the main function is created. main calls square_sum, a Stack frame for square_sum is created. square_sum calls sum, a Stack frame is created for sum. After sum is called, its Stack frame is destroyed, releasing automatically all the memory it occupied. After square_sum is called, its Stack frame is destroyed, releasing automatically all the memory it occupied. main prints the result and ends. The operating system frees up all the remaining memory. NOTE: Usually, the stack grow downwards!\nInside the Stack frame The Stack frame is where all the local variables, arguments, and return address (this is used by the running process to know where the next code instruction to be executed is, after the function call ends) of a function live. The good news is that the user does not have to worry about allocating or de-allocating the memory used by it (neither with Heap allocations in safe Rust, but that is for another post). Given that the Stack is fixed in size, we can only store data that its size is known at compile time. For dynamic sized data (such as vectors), Heap memory is used (only a pointer to that part of the Heap memory and maybe some metadata is saved into the Stack). Let\u0026rsquo;s expand the above Stack diagrams to show the stack frame of each function:\nHow do we use the memory contained in the frame? We have two pointers that helps us with that:\nStack Pointer (SP): Always points at the top of the Stack. When a Stack frame is created the new SP\u0026rsquo;s value is SP + size_of(new_Stack_frame). It will change any time a value is pushed onto or popped off the stack. When an executing function returns, it goes back to its previous size. Base Pointer (BP): Also known as Frame Pointer (FP). Points to the base of the current Stack frame. When a Stack frame is created, the BP gets the value SP had before adding the size of the new Stack frame. The BP is used to access the arguments and local variables of a function by adding/substracting the offset of the variable we want to access. For example, if we want to access the argument y, we need to read the address BP + 12 because, first, we have the return address that (let\u0026rsquo;s assume) is 4 bytes long, and then the argument x that is a 32 bits integer (4 bytes). The layout presented here is just an example. Although, in reality, the frames contain the same information, how the data is organized depends on the machine architecture and the application binary interface (ABI).\nThis StackOverflow answer shows how the frame is constructed using x86 assembly.\nHeap In this context, \u0026ldquo;Heap\u0026rdquo; has nothing to do with the Heap data structure, it is just a name for the free memory pool.\nThe Heap is not fixed in size. We can ask for more memory, as long as it is available in the system, and free it if the allocated values are not needed anymore. Unlike Stack, when we are working with the Heap we have to take care of the allocation and deallocation of memory (in Rust, most allocation/deallocation logic is hidden behind abstractions). When we use the Heap, we are dynamically allocating memory. This comes in very handy when we are dealing with data which size is unknown at compile time (i.e. user input). In opposition to the Stack, the memory allocations are not sequential.\nWhen a process wants to allocate some chunk of memory of a given size, the operating system first has to search for a free piece of memory with the needed size. After finding it, the OS locks it up (only that particular process can access that portion of the system memory) and returns the starting address of the block. This process leads to memory fragmentation (the data allocated in the Heap is not contiguous).\nWhen we use the Heap, we also store some data in the Stack (at least a pointer to the allocated data). Consider the following code:\nfn main() { let n1: Box\u0026lt;u8\u0026gt; = Box::new(42); let my_string = String::from(\u0026#34;hello\u0026#34;); println!(\u0026#34;{} {}\u0026#34;, my_string, n1); } NOTE: A Box is a smart pointer to a heap allocated value.\nThe following diagram shows the allocations made in the Stack and the Heap:\nWriting and reading the Heap is slower than writing and reading the Stack for several reasons:\nFor memory allocation, a process has to make a system call and wait for the OS to complete the process described above. Using the allocated memory (for writing or reading) involves at least one indirection (following the pointer allocated in the Stack). Under the right conditions, a program can be optimized to store some parts of the Stack inside the processor\u0026rsquo;s cache, making writing/reading operations blazingly fast. Summary Stack Heap Fixed in size Can grow or shrink Allocations are in a contiguous block Allocation happens in \u0026ldquo;random\u0026rdquo; order Faster access time Slower access time Is thread local by default: every thread of a process has its own Stack. Can be used to share memory across threads ","permalink":"https://nicoan.github.io/posts/stack_and_heap/","summary":"Why write about Stack and Heap when there are already a lot of articles out there? I want to improve my writing skills so, I decided to write articles about things I find interesting. This article was supposed to be about how Rust manages memory through ownership. Then I thought \u0026ldquo;I should first write about Stack and Heap\u0026rdquo;. So, here we are).\nTo understand memory management first, we need to understand what the Stack and the Heap are.","title":"Stack and Heap"}]